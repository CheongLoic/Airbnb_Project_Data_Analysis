pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100,1)
barplot(pca.var.per, main = "Poids des variables dans les composants principaux", xlab = "Principal Component", ylab = "Percent Variation")
pca.data <- data.frame(Sample=rownames(pca$x), X= pca$x[,1],  Y= pca$x[,2])
pca.data
ggplot(data = pca.data, aes(x=X, y=Y, label = Sample)) + geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep=""))+
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw()+
ggtitle("ACP")
library(varhandle)
ACP_France <- ewcs_2015_filtree %>% filter(pays ==1 ) %>% select(-pays)
ACP_France <- unfactor(ACP_France)
pca <- prcomp(t(ACP_France),  scale = TRUE)
plot(pca$x[,1],pca$x[,2] )
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100,1)
barplot(pca.var.per, main = "Poids des variables dans les composants principaux - France", xlab = "Principal Component", ylab = "Percent Variation")
pca.data <- data.frame(Sample=rownames(pca$x), X= pca$x[,1],  Y= pca$x[,2])
pca.data
ggplot(data = pca.data, aes(x=X, y=Y, label = Sample)) + geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep=""))+
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw()+
ggtitle("ACP France")
ACP_Italy <- ewcs_2015_filtree %>% filter(pays ==2 ) %>% select(-pays)
ACP_Italy <- unfactor(ACP_Italy)
pca <- prcomp(t(ACP_Italy),  scale = TRUE)
plot(pca$x[,1],pca$x[,2] )
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100,1)
barplot(pca.var.per, main = "Poids des variables dans les composants principaux - Italie", xlab = "Principal Component", ylab = "Percent Variation")
pca.data <- data.frame(Sample=rownames(pca$x), X= pca$x[,1],  Y= pca$x[,2])
pca.data
ggplot(data = pca.data, aes(x=X, y=Y, label = Sample)) + geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep=""))+
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw()+
ggtitle("ACP Italie")
plot(pca$x[,1],pca$x[,2] ) + xlab("PC1") + ylab("PC2")
plot(pca$x[,1],pca$x[,2] ,  xlab="PC1", ylab="PC2")
ACP_France <- ewcs_2015_filtree %>% filter(pays ==1 ) %>% select(-pays)
ACP_France <- unfactor(ACP_France)
pca <- prcomp(t(ACP_France),  scale = TRUE) #Cacul du ACP, en normant les données de 0 à 1
plot(pca$x[,1],pca$x[,2] ,  xlab="PC1", ylab="PC2")
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100,1)
barplot(pca.var.per, main = "Poids des variables dans les composants principaux - France", xlab = "Principal Component", ylab = "Percent Variation")
pca.data <- data.frame(Sample=rownames(pca$x), X= pca$x[,1],  Y= pca$x[,2])
pca.data
ggplot(data = pca.data, aes(x=X, y=Y, label = Sample)) + geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep=""))+
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw()+
ggtitle("ACP France")
##################################
ACP_Italy <- ewcs_2015_filtree %>% filter(pays ==2 ) %>% select(-pays)
ACP_Italy <- unfactor(ACP_Italy)
pca <- prcomp(t(ACP_Italy),  scale = TRUE)
plot(pca$x[,1],pca$x[,2] ,  xlab="PC1", ylab="PC2")
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100,1)
barplot(pca.var.per, main = "Poids des variables dans les composants principaux - Italie", xlab = "Principal Component", ylab = "Percent Variation")
pca.data <- data.frame(Sample=rownames(pca$x), X= pca$x[,1],  Y= pca$x[,2])
pca.data
ggplot(data = pca.data, aes(x=X, y=Y, label = Sample)) + geom_text() +
xlab(paste("PC1 - ", pca.var.per[1], "%", sep=""))+
ylab(paste("PC2 - ", pca.var.per[2], "%", sep="")) +
theme_bw()+
ggtitle("ACP Italie")
View(ACP_France)
View(ACP_Italy)
View(ACP_France)
View(ACP_Italy)
View(ACP_France)
ACP_France[-14]
ACP_France[-1]
ACP_France[1]
View(g)
View(aggIT)
aggIT[-3]
aggIT[-1]
aggIT[-2]
aggIT[-3]
1+2
install.packages("rlang")
install.packages("ggplot2")
getwd()
?predict
shiny::runApp('C:/Users/LOL/Desktop/LOIC/ECE/ING5/Data Analysis with R/Project/Airbnb_Project_Data_Analysis/App')
?menuItem
install.packages('rsconnect')
rsconnect::setAccountInfo(name='loiccheong', token='8F2096A865353D9EEDA60AA4C6CA1AB8', secret='V3Pn1jXl3+Wc1RnmyjFv7UVLejMWVTVAmaGhmGRX')
getwd()
#chemin Charl?ne
# setwd("C:/Users/user/Documents/ING5/Data Analytics/Projet/Airbnb_Project_Data_Analysis/App")
#chemin Loic
setwd("C:/Users/LOL/Desktop/LOIC/ECE/ING5/Data Analysis with R/Project/Airbnb_Project_Data_Analysis/App")
getwd()
runApp()
library(dplyr)
library(stringr)
library(ggplot2)
library(data.table)
#chemin Charl?ne
# setwd("C:/Users/user/Documents/ING5/Data Analytics/Projet/Airbnb_Project_Data_Analysis/App")
#chemin Loic
setwd("C:/Users/LOL/Desktop/LOIC/ECE/ING5/Data Analysis with R/Project/Airbnb_Project_Data_Analysis/App")
# chemin Pierre
#setwd("C:/Users/Pierre/Desktop/Airbnb_Project_Data_Analysis/App")
# chemin Anas
#setwd("C:\Users\admin123\Documents\GitHub\Airbnb_Project_Data_Analysis")
# a generic function to prepare data for a specific url,country,city, date
prepare_data <- function(url,country,city,date)
{
# Cleaning listings dataframe
#We load the data from the http link
tmp <- tempfile()
download.file(url,tmp)
listings <- read.csv(gzfile(tmp))
# Add Keys: columns country,city and day date
listings$country <- country
listings$city <- city
listings$date <- date
# Select interesting columns
columns_listings <- c("country","city", "date", "id", "neighbourhood_cleansed",
"latitude", "longitude",
"property_type", "room_type", "accommodates", "bedrooms",
"beds", "price", "minimum_nights",  "maximum_nights","availability_30")
listings <- listings %>%
select(which(names(.) %in% columns_listings)) %>%
arrange(id)
# clean price column and transform to numeric
listings$price <- as.numeric(str_remove(listings$price,"[$]"))
listings$price[is.na(listings$price)]<-0
listings$availability_30 <- as.numeric(listings$availability_30)
listings$availability_30[is.na(listings$availability_30)]<-30
#Add revenue_30
listings$revenue_30 <- listings$price *(30-listings$availability_30)
#write the cleansed data in csv
dir.create(file.path("../data/data_cleansed",country, city, date), recursive = TRUE)
write.csv(listings, file.path("../data/data_cleansed", country,city, date, "listings.csv"))
print(paste0("saving data into ", file.path("../data/data_cleansed", country,city,date, "listings.csv")))
}
decompose__filtered_urls <-function(){
#We get the list of urls
urls_path <- file.path("../data/all_data_urls.csv")
print(paste0("reading data from ", urls_path))
urls_data <- read.csv(urls_path)
#We split the url to add columns to filter later
url_decomposed <- str_split(urls_data$listings_data_url,"/",simplify = TRUE)
urls_data$country <- url_decomposed[,4]
urls_data$city <- url_decomposed[,6]
urls_data$date <- url_decomposed[,7]
#We filter the urls on countries and dates
#filter countries: Spain, France and Belgium
urls_data <-urls_data %>%
filter(country %in% c("france","spain","germany")) %>%
filter(city !="paris" ) %>%
arrange(country)
#filter dates: 3 first available dates
urls_data <-slice_head(urls_data%>%group_by(city), n = 3)
return(urls_data)
}
clean_all_data <- function(){
urls_data <- decompose__filtered_urls()
#Load data from selected urls
for(i in 1:nrow(urls_data)){
prepare_data(urls_data[i,]$listings_data_url,urls_data[i,]$country,urls_data[i,]$city,urls_data[i,]$date)
}
}
#Download the data
#clean_all_data() #Uncomment this line for the 1st running execution of the code
## Once data for multiple cities is prepared
## We can read this data and concatenate them together into one dataframe
read_cleansed_data <- function(){
# Reading cleansed data
countries <- c("france","germany","spain")
files_paths <- c()
# # Read data in cities
for(country in countries){
file_dir <- file.path("../data/", "data_cleansed", country)
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
for(file_subdir_city in file_subdirs_cities){
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=FALSE)
files_paths <- c(files_paths, file_subdirs_dates)
}
}
files_paths <- file.path(files_paths, "listings.csv")
#print(files_paths)
listings <-
do.call(rbind,
lapply(files_paths, read.csv, row.names=1))
# ## Preprocess
listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
return(listings)
}
library(dplyr)
library(stringr)
library(ggplot2)
library(data.table)
#chemin Charl?ne
# setwd("C:/Users/user/Documents/ING5/Data Analytics/Projet/Airbnb_Project_Data_Analysis/App")
#chemin Loic
setwd("C:/Users/LOL/Desktop/LOIC/ECE/ING5/Data Analysis with R/Project/Airbnb_Project_Data_Analysis/App")
# chemin Pierre
#setwd("C:/Users/Pierre/Desktop/Airbnb_Project_Data_Analysis/App")
# chemin Anas
#setwd("C:\Users\admin123\Documents\GitHub\Airbnb_Project_Data_Analysis")
# a generic function to prepare data for a specific url,country,city, date
prepare_data <- function(url,country,city,date)
{
# Cleaning listings dataframe
#We load the data from the http link
tmp <- tempfile()
download.file(url,tmp)
listings <- read.csv(gzfile(tmp))
# Add Keys: columns country,city and day date
listings$country <- country
listings$city <- city
listings$date <- date
# Select interesting columns
columns_listings <- c("country","city", "date", "id", "neighbourhood_cleansed",
"latitude", "longitude",
"property_type", "room_type", "accommodates", "bedrooms",
"beds", "price", "minimum_nights",  "maximum_nights","availability_30")
listings <- listings %>%
select(which(names(.) %in% columns_listings)) %>%
arrange(id)
# clean price column and transform to numeric
listings$price <- as.numeric(str_remove(listings$price,"[$]"))
listings$price[is.na(listings$price)]<-0
listings$availability_30 <- as.numeric(listings$availability_30)
listings$availability_30[is.na(listings$availability_30)]<-30
#Add revenue_30
listings$revenue_30 <- listings$price *(30-listings$availability_30)
#write the cleansed data in csv
dir.create(file.path("../data/data_cleansed",country, city, date), recursive = TRUE)
write.csv(listings, file.path("../data/data_cleansed", country,city, date, "listings.csv"))
print(paste0("saving data into ", file.path("../data/data_cleansed", country,city,date, "listings.csv")))
}
decompose__filtered_urls <-function(){
#We get the list of urls
urls_path <- file.path("../data/all_data_urls.csv")
print(paste0("reading data from ", urls_path))
urls_data <- read.csv(urls_path)
#We split the url to add columns to filter later
url_decomposed <- str_split(urls_data$listings_data_url,"/",simplify = TRUE)
urls_data$country <- url_decomposed[,4]
urls_data$city <- url_decomposed[,6]
urls_data$date <- url_decomposed[,7]
#We filter the urls on countries and dates
#filter countries: Spain, France and Belgium
urls_data <-urls_data %>%
filter(country %in% c("france","spain","germany")) %>%
filter(city !="paris" ) %>%
arrange(country)
#filter dates: 3 first available dates
urls_data <-slice_head(urls_data%>%group_by(city), n = 3)
return(urls_data)
}
clean_all_data <- function(){
urls_data <- decompose__filtered_urls()
#Load data from selected urls
for(i in 1:nrow(urls_data)){
prepare_data(urls_data[i,]$listings_data_url,urls_data[i,]$country,urls_data[i,]$city,urls_data[i,]$date)
}
}
#Download the data
#clean_all_data() #Uncomment this line for the 1st running execution of the code
## Once data for multiple cities is prepared
## We can read this data and concatenate them together into one dataframe
read_cleansed_data <- function(){
# Reading cleansed data
countries <- c("france","germany","spain")
files_paths <- c()
# # Read data in cities
for(country in countries){
file_dir <- file.path("../data/", "data_cleansed", country)
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
for(file_subdir_city in file_subdirs_cities){
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=FALSE)
files_paths <- c(files_paths, file_subdirs_dates)
}
}
files_paths <- file.path(files_paths, "listings.csv")
#print(files_paths)
listings <-
do.call(rbind,
lapply(files_paths, read.csv, row.names=1))
# ## Preprocess
listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
return(listings)
}
runApp()
getwd()
runApp()
View(mydata)
#global variable of the dataframe that contains all data read from CSV files
source("../Scripts/prepare_data.R")
mydata <- read_cleansed_data()
View(mydata)
View(mydata)
library(dplyr)
library(stringr)
library(ggplot2)
library(data.table)
#chemin Charl?ne
# setwd("C:/Users/user/Documents/ING5/Data Analytics/Projet/Airbnb_Project_Data_Analysis/App")
#chemin Loic
setwd("C:/Users/LOL/Desktop/LOIC/ECE/ING5/Data Analysis with R/Project/Airbnb_Project_Data_Analysis/App")
# chemin Pierre
#setwd("C:/Users/Pierre/Desktop/Airbnb_Project_Data_Analysis/App")
# chemin Anas
#setwd("C:\Users\admin123\Documents\GitHub\Airbnb_Project_Data_Analysis")
# a generic function to prepare data for a specific url,country,city, date
prepare_data <- function(url,country,city,date)
{
# Cleaning listings dataframe
#We load the data from the http link
tmp <- tempfile()
download.file(url,tmp)
listings <- read.csv(gzfile(tmp))
# Add Keys: columns country,city and day date
listings$country <- country
listings$city <- city
listings$date <- date
# Select interesting columns
columns_listings <- c("country","city", "date", "id", "neighbourhood_cleansed",
"latitude", "longitude",
"property_type", "room_type", "accommodates", "bedrooms",
"beds", "price", "minimum_nights",  "maximum_nights","availability_30")
listings <- listings %>%
select(which(names(.) %in% columns_listings)) %>%
arrange(id)
# clean price column and transform to numeric
listings$price <- as.numeric(str_remove(listings$price,"[$]"))
listings$price[is.na(listings$price)]<-0
listings$availability_30 <- as.numeric(listings$availability_30)
listings$availability_30[is.na(listings$availability_30)]<-30
#Add revenue_30
listings$revenue_30 <- listings$price *(30-listings$availability_30)
#write the cleansed data in csv
dir.create(file.path("../data/data_cleansed",country, city, date), recursive = TRUE)
write.csv(listings, file.path("../data/data_cleansed", country,city, date, "listings.csv"))
print(paste0("saving data into ", file.path("../data/data_cleansed", country,city,date, "listings.csv")))
}
decompose__filtered_urls <-function(){
#We get the list of urls
urls_path <- file.path("../data/all_data_urls.csv")
print(paste0("reading data from ", urls_path))
urls_data <- read.csv(urls_path)
#We split the url to add columns to filter later
url_decomposed <- str_split(urls_data$listings_data_url,"/",simplify = TRUE)
urls_data$country <- url_decomposed[,4]
urls_data$city <- url_decomposed[,6]
urls_data$date <- url_decomposed[,7]
#We filter the urls on countries and dates
#filter countries: Spain, France and Belgium
urls_data <-urls_data %>%
filter(country %in% c("france","spain","germany")) %>%
filter(city !="paris" ) %>%
arrange(country)
#filter dates: 3 first available dates
urls_data <-slice_head(urls_data%>%group_by(city), n = 3)
return(urls_data)
}
clean_all_data <- function(){
urls_data <- decompose__filtered_urls()
#Load data from selected urls
for(i in 1:nrow(urls_data)){
prepare_data(urls_data[i,]$listings_data_url,urls_data[i,]$country,urls_data[i,]$city,urls_data[i,]$date)
}
}
#Download the data
#clean_all_data() #Uncomment this line for the 1st running execution of the code
## Once data for multiple cities is prepared
## We can read this data and concatenate them together into one dataframe
read_cleansed_data <- function(){
# Reading cleansed data
countries <- c("france","germany","spain")
files_paths <- c()
# # Read data in cities
for(country in countries){
file_dir <- file.path("../data/", "data_cleansed", country)
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
for(file_subdir_city in file_subdirs_cities){
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=FALSE)
files_paths <- c(files_paths, file_subdirs_dates)
}
}
files_paths <- file.path(files_paths, "listings.csv")
#print(files_paths)
listings <-
do.call(rbind,
lapply(files_paths, read.csv, row.names=1))
# ## Preprocess
listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
return(listings)
}
mydata <- read_cleansed_data()
decompose__filtered_urls
mydata <- read_cleansed_data()
mydata <- clean_all_data()
runApp()
mydata <- read_cleansed_data()
print("Getting data from", "jghv")
print(paste("Getting data from", "jghv"))
read_cleansed_data <- function(){
# Reading cleansed data
countries <- c("france","germany","spain")
files_paths <- c()
# # Read data in cities
for(country in countries){
print(paste("Getting data from", country))
file_dir <- file.path("../data/", "data_cleansed", country)
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
for(file_subdir_city in file_subdirs_cities){
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=FALSE)
files_paths <- c(files_paths, file_subdirs_dates)
}
}
files_paths <- file.path(files_paths, "listings.csv")
print(files_paths)
listings <-
do.call(rbind,
lapply(files_paths, read.csv, row.names=1))
# ## Preprocess
listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
return(listings)
}
mydata <- read_cleansed_data()
read_cleansed_data <- function(){
# Reading cleansed data
countries <- c("france","germany","spain")
files_paths <- c()
# # Read data in cities
for(country in countries){
print(paste("Getting data from", country))
file_dir <- file.path("../data/", "data_cleansed", country)
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
for(file_subdir_city in file_subdirs_cities){
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=FALSE)
files_paths <- c(files_paths, file_subdirs_dates)
}
}
files_paths <- file.path(files_paths, "listings.csv")
print(files_paths)
listings <-
do.call(rbind,
lapply(files_paths, read.csv, row.names=1))
# ## Preprocess
listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
print("END of function")
return(listings)
}
mydata <- read_cleansed_data()
countries <- c("france","germany","spain")
files_paths <- c()
# # Read data in cities
for(country in countries){
print(paste("Getting data from", country))
file_dir <- file.path("../data/", "data_cleansed", country)
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
for(file_subdir_city in file_subdirs_cities){
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=FALSE)
files_paths <- c(files_paths, file_subdirs_dates)
}
}
files_paths <- file.path(files_paths, "listings.csv")
print(files_paths)
listings <-
do.call(rbind,
lapply(files_paths, read.csv, row.names=1))
# ## Preprocess
listings$bedrooms <- ifelse(listings$bedrooms >= 5, "5+", listings$bedrooms)
print("END of function")
View(listings)
file_dir
file_subdirs_cities
files_paths
list.dirs(file_dir)
file_dir
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
file_subdirs_cities
?list.dirs
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=TRUE)
FALSE
file_subdirs_dates <- list.dirs(file_subdir_city,recursive=FALSE)
file_subdirs_cities <- list.dirs(file_dir,recursive=FALSE)
file_subdirs_cities <- list.dirs(file_dir,recursive=TRUE)
file_subdirs_cities
runApp('C:/Users/LOL/Desktop/shiny')
runApp('C:/Users/LOL/Desktop/shiny')
deployApp('C:/Users/LOL/Desktop/shiny')
runApp('C:/Users/LOL/Desktop/shiny')
library(rsconnect)
deployApp()
runApp('C:/Users/LOL/Desktop/shiny')
my_data <- read_cleansed_data()
View(my_data)
rm(my_data)
runApp()
runApp()
install.packages("cachem")  # Met à jour cachem à la dernière version
install.packages("rlang")   # Met à jour rlang à la dernière version
install.packages("cachem")
install.packages("rlang")
runApp()
library(shiny)
library(fontawesome)
runApp()
